{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use color, just append color.BOLD to the beginning of the printed string and color.END to the end:\n",
      "\u001b[1mLike This!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('To use color, just append color.BOLD to the beginning of the printed string and color.END to the end:')\n",
    "print(color.BOLD + 'Like This!' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the mean absolute error:\n",
    "$$\n",
    "MAE = \\frac{1}{N}\\sum_{i=1}^N |y_i-x_i^\\top\\theta|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAE(theta, X, y):\n",
    "    # --------------\n",
    "    # Your Code Here\n",
    "    # This function should return the mean absolute error\n",
    "    # --------------\n",
    "    y_real = X@theta\n",
    "    N_mae = len(y)\n",
    "    p = cp.norm(y - y_real)\n",
    "    mae =((1/N_mae) * cp.sum(p)).value\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, X_test, Y, Y_test = train_test_split(diabetes['data'], \n",
    "                                        np.expand_dims(diabetes['target'], 1), \n",
    "                                        test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "Implement below the mean-absolute error regression with LASSO. Use $\\lambda=0.5$. Hints: in the X matrix, rows represent data samples. Also, don't forget to add the `1` column to capture the intercept. (Use the `GLPK` solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mWith GLPK solution of LP =\u001b[0m 120.48642533936652\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ones_X = np.ones((X.shape[0], 1))\n",
    "X = np.hstack ((Ones_X,X))\n",
    "Ones_X_test = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.hstack ((Ones_X_test,X_test))\n",
    "\n",
    "lamda = 0.5\n",
    "# Define the decision optimization variable\n",
    "N = X.shape[0]\n",
    "d = X.shape[1]\n",
    "z = cp.Variable((N, 1))\n",
    "k = cp.Variable((d, 1))\n",
    "theta = cp.Variable(shape=(11,1),name='theta')\n",
    "# Define an array containing all the constraints\n",
    "constraints = [\n",
    "    Y-X@theta <= z,\n",
    "    -Y+X@theta <= z,\n",
    "    theta <= k,\n",
    "    -theta <= k,\n",
    "    z >= 0\n",
    "]\n",
    "# Define the objective: to minimize (cp.Minimize)\n",
    "objective  = cp.Minimize((1/N)*cp.sum(z) + lamda*cp.sum(k))           \n",
    "# First combine the objective and constraints to formulate the problem using cp.Problem\n",
    "# Use .solve() on the problem to solve the problem\n",
    "problem = cp.Problem(objective, constraints)\n",
    "\n",
    "print('\\n')\n",
    "print(color.BOLD+'With GLPK solution of LP ='+color.END,problem.solve(solver=cp.GLPK))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Results\u001b[0m\n",
      "MAE: 7.126487104577589\n",
      "\n",
      "\n",
      "\u001b[1mTest Results\u001b[0m\n",
      "MAE: 6.9763102871841065\n"
     ]
    }
   ],
   "source": [
    "print(color.BOLD + 'Training Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(theta, X, Y)))\n",
    "print('\\n')\n",
    "print(color.BOLD + 'Test Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(theta, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3\n",
    "Implement Cross-Validation for your MAE LASSO regression. You may recycle any functions used above. Hint: Use the `sklearn` function `train_test_split`, which can be used to randomly split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest lamda\u001b[0m\n",
      "Lamda: 0.0033932217718953264\n",
      "\u001b[1mBest theta\u001b[0m\n",
      "Theta: [[ 148.27219259]\n",
      " [   0.        ]\n",
      " [-164.12936595]\n",
      " [ 457.06579556]\n",
      " [ 433.09645823]\n",
      " [   0.        ]\n",
      " [   0.        ]\n",
      " [-237.99709241]\n",
      " [   0.        ]\n",
      " [ 376.0943771 ]\n",
      " [   5.17444167]]\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Your Code Here\n",
    "# --------------\n",
    "def MAE_Lasso_solver(X,Y,X_test,Y_test,l):\n",
    "    \n",
    "    # Define the decision optimization variable\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    z = cp.Variable((N, 1))\n",
    "    k = cp.Variable((d, 1))\n",
    "    theta = cp.Variable(shape=(d,1),name='theta')\n",
    "    # Define an array containing all the constraints\n",
    "    constraints = [\n",
    "        Y-X@theta <= z,\n",
    "        -Y+X@theta <= z,\n",
    "        theta <= k,\n",
    "        -theta <= k,\n",
    "        z >= 0\n",
    "    ]\n",
    "    # Define the objective: to minimize (cp.Minimize)\n",
    "    objective  = cp.Minimize((1/N)*cp.sum(z) + l*cp.sum(k))           \n",
    "    # First combine the objective and constraints to formulate the problem using cp.Problem\n",
    "    # Use .solve() on the problem to solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.GLPK)\n",
    "\n",
    "    return theta\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X, X_test, Y, Y_test = train_test_split(diabetes['data'], \n",
    "                                        np.expand_dims(diabetes['target'], 1), \n",
    "                                        test_size=0.25, random_state=42)\n",
    "\n",
    "Ones_X = np.ones((X.shape[0], 1))\n",
    "X = np.hstack ((Ones_X,X))\n",
    "Ones_X_test = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.hstack ((Ones_X_test,X_test))\n",
    "\n",
    "train, test, thetas = [], [], []\n",
    "\n",
    "# Hyperparameter:\n",
    "lamda = np.logspace(-5, -1, 50, base = 10)\n",
    "\n",
    "# Cross-validation:\n",
    "for l in lamda:\n",
    "    theta = MAE_Lasso_solver(X, Y, X_test, Y_test, l)\n",
    "    thetas.append(theta)\n",
    "    train.append(get_MAE(theta, X, Y))\n",
    "    test.append(get_MAE(theta, X_test, Y_test))\n",
    "    \n",
    "best_lamda = lamda[np.argmin(test)]\n",
    "best_theta = thetas[np.argmin(test)]\n",
    "\n",
    "print(color.BOLD + 'Best lamda' + color.END)\n",
    "print('Lamda: {}'.format(best_lamda))\n",
    "\n",
    "print(color.BOLD + 'Best theta' + color.END)\n",
    "print('Theta: {}'.format(best_theta.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining Results\u001b[0m\n",
      "MAE: 3.0392929514777043\n",
      "\n",
      "\n",
      "\u001b[1mTest Results\u001b[0m\n",
      "MAE: 5.011492732640858\n"
     ]
    }
   ],
   "source": [
    "print(color.BOLD + 'Training Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(best_theta, X, Y)))\n",
    "print('\\n')\n",
    "print(color.BOLD + 'Test Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(best_theta, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
